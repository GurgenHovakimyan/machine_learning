{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import random\n",
    "\n",
    "def trainTestSplit(dataFrame, testSize):\n",
    "    if isinstance(testSize, float):\n",
    "        testSize = round(testSize * len(dataFrame))\n",
    "    indices = dataFrame.index.tolist()\n",
    "    testIndices = random.sample(population = indices, k = testSize)\n",
    "    dataFrameTest = dataFrame.loc[testIndices]\n",
    "    dataFrameTrain = dataFrame.drop(testIndices)\n",
    "    return dataFrameTrain, dataFrameTest\n",
    "\n",
    "def checkPurity(data):\n",
    "    if len(numpy.unique(data[:, -1])) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def classifyData(data):\n",
    "    uniqueClasses, uniqueClassesCounts = numpy.unique(data[:, -1], return_counts = True)\n",
    "    return uniqueClasses[uniqueClassesCounts.argmax()]\n",
    "\n",
    "def getPotentialSplits(data, randomAttributes):\n",
    "    potentialSplits = {}\n",
    "    _, columns = data.shape\n",
    "    columnsIndices = list(range(columns - 1))\n",
    "    if randomAttributes != None  and len(randomAttributes) <= len(columnsIndices):\n",
    "        columnsIndices = randomAttributes\n",
    "    for column in columnsIndices:\n",
    "        values = data[:, column]\n",
    "        uniqueValues = numpy.unique(values)\n",
    "        if len(uniqueValues) == 1:\n",
    "            potentialSplits[column] = uniqueValues\n",
    "        else:\n",
    "            potentialSplits[column] = []\n",
    "            for i in range(len(uniqueValues)):\n",
    "                if i != 0:\n",
    "                    currentValue = uniqueValues[i]\n",
    "                    previousValue = uniqueValues[i - 1]\n",
    "                    potentialSplits[column].append((currentValue + previousValue) / 2)\n",
    "    return potentialSplits\n",
    "\n",
    "def splitData(data, splitColumn, splitValue):\n",
    "    splitColumnValues = data[:, splitColumn]\n",
    "    return data[splitColumnValues <= splitValue], data[splitColumnValues > splitValue]\n",
    "\n",
    "def calculateEntropy(data):\n",
    "    _, uniqueClassesCounts = numpy.unique(data[:, -1], return_counts = True)\n",
    "    probabilities = uniqueClassesCounts / uniqueClassesCounts.sum()\n",
    "    return sum(probabilities * -numpy.log2(probabilities))\n",
    "\n",
    "def calculateOverallEntropy(dataBelow, dataAbove):\n",
    "    pDataBelow = len(dataBelow) / (len(dataBelow) + len(dataAbove))\n",
    "    pDataAbove = len(dataAbove) / (len(dataBelow) + len(dataAbove))\n",
    "    return pDataBelow * calculateEntropy(dataBelow) + pDataAbove * calculateEntropy(dataAbove)\n",
    "\n",
    "def determineBestSplit(data, potentialSplits, randomSplits = None):\n",
    "    overallEntropy = 9999\n",
    "    bestSplitColumn = 0\n",
    "    bestSplitValue = 0\n",
    "    if randomSplits == None:\n",
    "        for splitColumn in potentialSplits:\n",
    "            for splitValue in potentialSplits[splitColumn]:\n",
    "                dataBelow, dataAbove = splitData(data, splitColumn, splitValue)\n",
    "                currentOverallEntropy = calculateOverallEntropy(dataBelow, dataAbove)\n",
    "                if currentOverallEntropy <= overallEntropy:\n",
    "                    overallEntropy = currentOverallEntropy\n",
    "                    bestSplitColumn = splitColumn\n",
    "                    bestSplitValue = splitValue\n",
    "    else:\n",
    "        for i in range(randomSplits):\n",
    "            randomSplitColumn = random.choice(list(potentialSplits))\n",
    "            randomSplitValue = random.choice(potentialSplits[randomSplitColumn])\n",
    "            dataBelow, dataAbove = splitData(data, randomSplitColumn, randomSplitValue)\n",
    "            currentOverallEntropy = calculateOverallEntropy(dataBelow, dataAbove)\n",
    "            if currentOverallEntropy <= overallEntropy:\n",
    "                overallEntropy = currentOverallEntropy\n",
    "                bestSplitColumn = randomSplitColumn\n",
    "                bestSplitValue = randomSplitValue\n",
    "    return bestSplitColumn, bestSplitValue\n",
    "\n",
    "def buildDecisionTree(dataFrame, currentDepth = 0, minSampleSize = 2, maxDepth = 1000, randomAttributes = None, randomSplits = None):\n",
    "    if currentDepth == 0:\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = dataFrame.columns\n",
    "        data = dataFrame.values\n",
    "        if randomAttributes != None and randomAttributes <= len(COLUMN_HEADERS) - 1:\n",
    "            randomAttributes = random.sample(population = list(range(len(COLUMN_HEADERS) - 1)), k = randomAttributes)\n",
    "        else:\n",
    "            randomAttributes = None\n",
    "    else:\n",
    "        data = dataFrame\n",
    "    if checkPurity(data) or len(data) < minSampleSize or currentDepth == maxDepth:\n",
    "        return classifyData(data)\n",
    "    else:\n",
    "        currentDepth += 1\n",
    "        potentialSplits = getPotentialSplits(data, randomAttributes)\n",
    "        splitColumn, splitValue = determineBestSplit(data, potentialSplits, randomSplits)\n",
    "        dataBelow, dataAbove = splitData(data, splitColumn, splitValue)\n",
    "        if len(dataBelow) == 0 or len(dataAbove) == 0:\n",
    "            return classifyData(data)\n",
    "        else:\n",
    "            question = str(COLUMN_HEADERS[splitColumn]) + \" <= \" + str(splitValue)\n",
    "            decisionSubTree = {question: []}\n",
    "            yesAnswer = buildDecisionTree(dataBelow, currentDepth, minSampleSize, maxDepth, randomAttributes, randomSplits)\n",
    "            noAnswer = buildDecisionTree(dataAbove, currentDepth, minSampleSize, maxDepth, randomAttributes, randomSplits)\n",
    "            if yesAnswer == noAnswer:\n",
    "                decisionSubTree = yesAnswer\n",
    "            else:\n",
    "                decisionSubTree[question].append(yesAnswer)\n",
    "                decisionSubTree[question].append(noAnswer)\n",
    "            return decisionSubTree\n",
    "\n",
    "def classifySample(sample, decisionTree):\n",
    "    if not isinstance(decisionTree, dict):\n",
    "        return decisionTree\n",
    "    question = list(decisionTree.keys())[0]\n",
    "    attribute, value = question.split(\" <= \")\n",
    "    if sample[attribute] <= float(value):\n",
    "        answer = decisionTree[question][0]\n",
    "    else:\n",
    "        answer = decisionTree[question][1]\n",
    "    return classifySample(sample, answer)\n",
    "\n",
    "def decisionTreePredictions(dataFrame, decisionTree):\n",
    "    predictions = dataFrame.apply(classifySample, axis = 1, args = (decisionTree,))\n",
    "    return predictions\n",
    "\n",
    "def calculateAccuracy(predictedResults, category):\n",
    "    resultCorrect = predictedResults == category\n",
    "    return resultCorrect.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Car Evaluation Dataset\n",
      "maxDepth = 1: accTest = 70.08%, accTrain = 70.00%, buildTime = 0.01s\n",
      "maxDepth = 2: accTest = 76.83%, accTrain = 78.18%, buildTime = 0.02s\n",
      "maxDepth = 3: accTest = 78.57%, accTrain = 79.42%, buildTime = 0.02s\n",
      "maxDepth = 4: accTest = 83.78%, accTrain = 83.64%, buildTime = 0.02s\n",
      "maxDepth = 5: accTest = 87.26%, accTrain = 87.27%, buildTime = 0.03s\n",
      "maxDepth = 6: accTest = 92.47%, accTrain = 91.74%, buildTime = 0.04s\n",
      "maxDepth = 7: accTest = 93.24%, accTrain = 94.38%, buildTime = 0.05s\n",
      "maxDepth = 8: accTest = 96.33%, accTrain = 97.02%, buildTime = 0.05s\n",
      "maxDepth = 9: accTest = 97.10%, accTrain = 98.43%, buildTime = 0.07s\n",
      "maxDepth = 10: accTest = 98.26%, accTrain = 99.59%, buildTime = 0.08s\n",
      "maxDepth = 11: accTest = 98.65%, accTrain = 99.92%, buildTime = 0.09s\n",
      "maxDepth = 12: accTest = 98.65%, accTrain = 100.00%, buildTime = 0.09s\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas\n",
    "import time\n",
    "\n",
    "# Get the data from the Google Drive Dataset_files\n",
    "dataFrame = pandas.read_csv(\"Decision Tree/dataset_files/car_evaluation.csv\")\n",
    "\n",
    "buyingMapping = {\"low\": 1, \"med\": 2, \"high\": 3, \"vhigh\": 4}\n",
    "dataFrame[\"buying\"] = dataFrame[\"buying\"].map(buyingMapping)\n",
    "\n",
    "maintMapping = {\"low\": 1, \"med\": 2, \"high\": 3, \"vhigh\": 4}\n",
    "dataFrame[\"maint\"] = dataFrame[\"maint\"].map(maintMapping)\n",
    "\n",
    "doorsMapping = {\"2\": 2, \"3\": 3, \"4\": 4, \"5more\": 5}\n",
    "dataFrame[\"doors\"] = dataFrame[\"doors\"].map(doorsMapping)\n",
    "\n",
    "personsMapping = {\"2\": 2, \"4\": 4, \"more\": 6}\n",
    "dataFrame[\"persons\"] = dataFrame[\"persons\"].map(personsMapping)\n",
    "\n",
    "lugBootMapping = {\"small\": 1, \"med\": 2, \"big\": 3}\n",
    "dataFrame[\"lug_boot\"] = dataFrame[\"lug_boot\"].map(lugBootMapping)\n",
    "\n",
    "safetyMapping = {\"low\": 1, \"med\": 2, \"high\": 3}\n",
    "dataFrame[\"safety\"] = dataFrame[\"safety\"].map(safetyMapping)\n",
    "\n",
    "dataFrameTrain, dataFrameTest = trainTestSplit(dataFrame, testSize = 0.3)\n",
    "\n",
    "print(\"Decision Tree - Car Evaluation Dataset\")\n",
    "\n",
    "i = 1\n",
    "accuracyTrain = 0\n",
    "while accuracyTrain < 100:\n",
    "    startTime = time.time()\n",
    "    decisionTree = buildDecisionTree(dataFrameTrain, maxDepth = i)\n",
    "    buildingTime = time.time() - startTime\n",
    "    decisionTreeTestResults = decisionTreePredictions(dataFrameTest, decisionTree)\n",
    "    accuracyTest = calculateAccuracy(decisionTreeTestResults, dataFrameTest.iloc[:, -1]) * 100\n",
    "    decisionTreeTrainResults = decisionTreePredictions(dataFrameTrain, decisionTree)\n",
    "    accuracyTrain = calculateAccuracy(decisionTreeTrainResults, dataFrameTrain.iloc[:, -1]) * 100\n",
    "    print(\"maxDepth = {}: \".format(i), end = \"\")\n",
    "    print(\"accTest = {0:.2f}%, \".format(accuracyTest), end = \"\")\n",
    "    print(\"accTrain = {0:.2f}%, \".format(accuracyTrain), end = \"\")\n",
    "    print(\"buildTime = {0:.2f}s\".format(buildingTime), end = \"\\n\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
