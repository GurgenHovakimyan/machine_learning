{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:03:44.753736Z",
     "start_time": "2021-03-31T16:03:44.000522Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import random\n",
    "\n",
    "def trainTestSplit(dataFrame, testSize):\n",
    "    if isinstance(testSize, float):\n",
    "        testSize = round(testSize * len(dataFrame))\n",
    "    indices = dataFrame.index.tolist()\n",
    "    testIndices = random.sample(population = indices, k = testSize)\n",
    "    dataFrameTest = dataFrame.loc[testIndices]\n",
    "    dataFrameTrain = dataFrame.drop(testIndices)\n",
    "    return dataFrameTrain, dataFrameTest\n",
    "\n",
    "def checkPurity(data):\n",
    "    if len(numpy.unique(data[:, -1])) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def classifyData(data):\n",
    "    uniqueClasses, uniqueClassesCounts = numpy.unique(data[:, -1], return_counts = True)\n",
    "    return uniqueClasses[uniqueClassesCounts.argmax()]\n",
    "\n",
    "def getPotentialSplits(data, randomAttributes):\n",
    "    potentialSplits = {}\n",
    "    _, columns = data.shape\n",
    "    columnsIndices = list(range(columns - 1))\n",
    "    if randomAttributes != None  and len(randomAttributes) <= len(columnsIndices):\n",
    "        columnsIndices = randomAttributes\n",
    "    for column in columnsIndices:\n",
    "        values = data[:, column]\n",
    "        uniqueValues = numpy.unique(values)\n",
    "        if len(uniqueValues) == 1:\n",
    "            potentialSplits[column] = uniqueValues\n",
    "        else:\n",
    "            potentialSplits[column] = []\n",
    "            for i in range(len(uniqueValues)):\n",
    "                if i != 0:\n",
    "                    currentValue = uniqueValues[i]\n",
    "                    previousValue = uniqueValues[i - 1]\n",
    "                    potentialSplits[column].append((currentValue + previousValue) / 2)\n",
    "    return potentialSplits\n",
    "\n",
    "def splitData(data, splitColumn, splitValue):\n",
    "    splitColumnValues = data[:, splitColumn]\n",
    "    return data[splitColumnValues <= splitValue], data[splitColumnValues > splitValue]\n",
    "\n",
    "def calculateEntropy(data):\n",
    "    _, uniqueClassesCounts = numpy.unique(data[:, -1], return_counts = True)\n",
    "    probabilities = uniqueClassesCounts / uniqueClassesCounts.sum()\n",
    "    return sum(probabilities * -numpy.log2(probabilities))\n",
    "\n",
    "def calculateOverallEntropy(dataBelow, dataAbove):\n",
    "    pDataBelow = len(dataBelow) / (len(dataBelow) + len(dataAbove))\n",
    "    pDataAbove = len(dataAbove) / (len(dataBelow) + len(dataAbove))\n",
    "    return pDataBelow * calculateEntropy(dataBelow) + pDataAbove * calculateEntropy(dataAbove)\n",
    "\n",
    "def determineBestSplit(data, potentialSplits, randomSplits = None):\n",
    "    overallEntropy = 9999\n",
    "    bestSplitColumn = 0\n",
    "    bestSplitValue = 0\n",
    "    if randomSplits == None:\n",
    "        for splitColumn in potentialSplits:\n",
    "            for splitValue in potentialSplits[splitColumn]:\n",
    "                dataBelow, dataAbove = splitData(data, splitColumn, splitValue)\n",
    "                currentOverallEntropy = calculateOverallEntropy(dataBelow, dataAbove)\n",
    "                if currentOverallEntropy <= overallEntropy:\n",
    "                    overallEntropy = currentOverallEntropy\n",
    "                    bestSplitColumn = splitColumn\n",
    "                    bestSplitValue = splitValue\n",
    "    else:\n",
    "        for i in range(randomSplits):\n",
    "            randomSplitColumn = random.choice(list(potentialSplits))\n",
    "            randomSplitValue = random.choice(potentialSplits[randomSplitColumn])\n",
    "            dataBelow, dataAbove = splitData(data, randomSplitColumn, randomSplitValue)\n",
    "            currentOverallEntropy = calculateOverallEntropy(dataBelow, dataAbove)\n",
    "            if currentOverallEntropy <= overallEntropy:\n",
    "                overallEntropy = currentOverallEntropy\n",
    "                bestSplitColumn = randomSplitColumn\n",
    "                bestSplitValue = randomSplitValue\n",
    "    return bestSplitColumn, bestSplitValue\n",
    "\n",
    "def buildDecisionTree(dataFrame, currentDepth = 0, minSampleSize = 2, maxDepth = 1000, randomAttributes = None, randomSplits = None):\n",
    "    if currentDepth == 0:\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = dataFrame.columns\n",
    "        data = dataFrame.values\n",
    "        if randomAttributes != None and randomAttributes <= len(COLUMN_HEADERS) - 1:\n",
    "            randomAttributes = random.sample(population = list(range(len(COLUMN_HEADERS) - 1)), k = randomAttributes)\n",
    "        else:\n",
    "            randomAttributes = None\n",
    "    else:\n",
    "        data = dataFrame\n",
    "    if checkPurity(data) or len(data) < minSampleSize or currentDepth == maxDepth:\n",
    "        return classifyData(data)\n",
    "    else:\n",
    "        currentDepth += 1\n",
    "        potentialSplits = getPotentialSplits(data, randomAttributes)\n",
    "        splitColumn, splitValue = determineBestSplit(data, potentialSplits, randomSplits)\n",
    "        dataBelow, dataAbove = splitData(data, splitColumn, splitValue)\n",
    "        if len(dataBelow) == 0 or len(dataAbove) == 0:\n",
    "            return classifyData(data)\n",
    "        else:\n",
    "            question = str(COLUMN_HEADERS[splitColumn]) + \" <= \" + str(splitValue)\n",
    "            decisionSubTree = {question: []}\n",
    "            yesAnswer = buildDecisionTree(dataBelow, currentDepth, minSampleSize, maxDepth, randomAttributes, randomSplits)\n",
    "            noAnswer = buildDecisionTree(dataAbove, currentDepth, minSampleSize, maxDepth, randomAttributes, randomSplits)\n",
    "            if yesAnswer == noAnswer:\n",
    "                decisionSubTree = yesAnswer\n",
    "            else:\n",
    "                decisionSubTree[question].append(yesAnswer)\n",
    "                decisionSubTree[question].append(noAnswer)\n",
    "            return decisionSubTree\n",
    "\n",
    "def classifySample(sample, decisionTree):\n",
    "    if not isinstance(decisionTree, dict):\n",
    "        return decisionTree\n",
    "    question = list(decisionTree.keys())[0]\n",
    "    attribute, value = question.split(\" <= \")\n",
    "    if sample[attribute] <= float(value):\n",
    "        answer = decisionTree[question][0]\n",
    "    else:\n",
    "        answer = decisionTree[question][1]\n",
    "    return classifySample(sample, answer)\n",
    "\n",
    "def decisionTreePredictions(dataFrame, decisionTree):\n",
    "    predictions = dataFrame.apply(classifySample, axis = 1, args = (decisionTree,))\n",
    "    return predictions\n",
    "\n",
    "def calculateAccuracy(predictedResults, category):\n",
    "    resultCorrect = predictedResults == category\n",
    "    return resultCorrect.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:03:48.576883Z",
     "start_time": "2021-03-31T16:03:47.805584Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Decision Tree/dataset_files/car_evaluation.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fe300ea1fc0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Get the data from the Google Drive Dataset_files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdataFrame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Decision Tree/dataset_files/car_evaluation.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mbuyingMapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"low\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"med\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"high\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"vhigh\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Decision Tree/dataset_files/car_evaluation.csv'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas\n",
    "import time\n",
    "\n",
    "# Get the data from the Google Drive Dataset_files\n",
    "dataFrame = pandas.read_csv(\"Decision Tree/dataset_files/car_evaluation.csv\")\n",
    "\n",
    "buyingMapping = {\"low\": 1, \"med\": 2, \"high\": 3, \"vhigh\": 4}\n",
    "dataFrame[\"buying\"] = dataFrame[\"buying\"].map(buyingMapping)\n",
    "\n",
    "maintMapping = {\"low\": 1, \"med\": 2, \"high\": 3, \"vhigh\": 4}\n",
    "dataFrame[\"maint\"] = dataFrame[\"maint\"].map(maintMapping)\n",
    "\n",
    "doorsMapping = {\"2\": 2, \"3\": 3, \"4\": 4, \"5more\": 5}\n",
    "dataFrame[\"doors\"] = dataFrame[\"doors\"].map(doorsMapping)\n",
    "\n",
    "personsMapping = {\"2\": 2, \"4\": 4, \"more\": 6}\n",
    "dataFrame[\"persons\"] = dataFrame[\"persons\"].map(personsMapping)\n",
    "\n",
    "lugBootMapping = {\"small\": 1, \"med\": 2, \"big\": 3}\n",
    "dataFrame[\"lug_boot\"] = dataFrame[\"lug_boot\"].map(lugBootMapping)\n",
    "\n",
    "safetyMapping = {\"low\": 1, \"med\": 2, \"high\": 3}\n",
    "dataFrame[\"safety\"] = dataFrame[\"safety\"].map(safetyMapping)\n",
    "\n",
    "dataFrameTrain, dataFrameTest = trainTestSplit(dataFrame, testSize = 0.3)\n",
    "\n",
    "print(\"Decision Tree - Car Evaluation Dataset\")\n",
    "\n",
    "i = 1\n",
    "accuracyTrain = 0\n",
    "while accuracyTrain < 100:\n",
    "    startTime = time.time()\n",
    "    decisionTree = buildDecisionTree(dataFrameTrain, maxDepth = i)\n",
    "    buildingTime = time.time() - startTime\n",
    "    decisionTreeTestResults = decisionTreePredictions(dataFrameTest, decisionTree)\n",
    "    accuracyTest = calculateAccuracy(decisionTreeTestResults, dataFrameTest.iloc[:, -1]) * 100\n",
    "    decisionTreeTrainResults = decisionTreePredictions(dataFrameTrain, decisionTree)\n",
    "    accuracyTrain = calculateAccuracy(decisionTreeTrainResults, dataFrameTrain.iloc[:, -1]) * 100\n",
    "    print(\"maxDepth = {}: \".format(i), end = \"\")\n",
    "    print(\"accTest = {0:.2f}%, \".format(accuracyTest), end = \"\")\n",
    "    print(\"accTrain = {0:.2f}%, \".format(accuracyTrain), end = \"\")\n",
    "    print(\"buildTime = {0:.2f}s\".format(buildingTime), end = \"\\n\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
